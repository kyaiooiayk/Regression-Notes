{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style = \"border:2px solid black\" > </hr >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "**What?** Testing linear and non-linear regression model.\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear vs. non-linear methods\n",
    "<hr style = \"border:2px solid black\" > </hr >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "-  You cannot know which algorithms are best suited to your problem beforehand. \n",
    "- You must trial a number of methods and focus attention on those that prove themselves the most promising.\n",
    "<br><br>\n",
    "- **LINEAR**models:\n",
    "    - Linear Regression\n",
    "    - Ridge Regression\n",
    "    - LASSO Linear Regression\n",
    "    [- Elastic Net Regression\n",
    "- **NON-LINEAR** models:\n",
    "    - k-Nearest Neighbors\n",
    "    - Classification and Regression Trees\n",
    "    - Support Vector Machines\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules\n",
    "<hr style = \"border:2px solid black\" > </hr >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read-in the dataset\n",
    "<hr style = \"border:2px solid black\" > </hr >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape:  (506, 13)\n",
      "Labels shape (506,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_boston(return_X_y = True)\n",
    "Y = np.array(Y)\n",
    "print(\"Inputs shape: \", X.shape)\n",
    "print(\"Labels shape\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear models\n",
    "<hr style = \"border:2px solid black\" > </hr >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- Linear regression assumes that the input variables have a Gaussian distribution. \n",
    "- It is also assumed that input variables are relevant to the output variable and that they are not highly correlated with each other (a problem called COLLINEARITY).\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  -23.746501811313365\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 10, shuffle = True, random_state=7)\n",
    "model = LinearRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring = 'neg_mean_squared_error') \n",
    "print(\"Mean: \", results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- Ridge regression is an extension of linear regression where the loss function  is modified to minimize the complexity of the model measured as the sum squared value of the coefficient values (also called the L2-norm)  \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  -23.88989018505344\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 10, shuffle = True, random_state=7)\n",
    "model = Ridge()\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring = 'neg_mean_squared_error') \n",
    "print(\"Mean: \", results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- LASSO = Least Absolute Shrinkage and Selection Operator\n",
    "- It is a modification of linear regression, like ridge regression, where the loss function is modified to minimize the complexity of the model measured as the sum absolute value of the coefficient values (also called the L1-norm).\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  -28.74589007585154\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 10, shuffle = True, random_state=7)\n",
    "model = Lasso()\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring = 'neg_mean_squared_error') \n",
    "print(\"Mean: \", results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- ElasticNet is a form of regularization regression that combines the properties  of both Ridge Regression and LASSO regression. \n",
    "- It seeks to minimize the complexity of the regression model (magnitude and number of regression coefficients) by  penalizing the model using both the L2-norm (sum squared coefficient values) and  the L1-norm (sum absolute coefficient values)\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  -27.908420360231055\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 10, shuffle = True, random_state=7)\n",
    "model = ElasticNet()\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring = 'neg_mean_squared_error') \n",
    "print(\"Mean: \", results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear models\n",
    "<hr style = \"border:2px solid black\" > </hr >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- The k-Nearest Neighbors algorithm (or KNN) locates the k most similar instances  in the training dataset for a new data instance. \n",
    "- From the k neighbors, a mean or median output variable is taken as the prediction. Of note is the distance metric used (the metric argument). \n",
    "- The Minkowski distance is used by default, which is a generalization of both the Euclidean distance (used when all inputs  have the same scale) and Manhattan distance (for when the scales of the input  variables differ).\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  -38.852320266666666\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 10, shuffle = True, random_state=7)\n",
    "model = KNeighborsRegressor()\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring = 'neg_mean_squared_error') \n",
    "print(\"Mean: \", results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trees (CART)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- Decision trees or the Classification and Regression Trees (CART as they are known) use the training data to select the best points to split the data in order to  minimize a cost metric.\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  -22.831329411764706\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 10, shuffle = True, random_state=7)\n",
    "model = DecisionTreeRegressor()\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring = 'neg_mean_squared_error') \n",
    "print(\"Mean: \", results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- Support Vector Machines (SVM) were developed for binary classification.\n",
    "- The technique has been extended for the prediction real-valued problems called Support Vector Regression (SVR)\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  -67.64140705473743\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 10, shuffle = True, random_state=7)\n",
    "model = SVR()\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring = 'neg_mean_squared_error') \n",
    "print(\"Mean: \", results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "<hr style = \"border:2px solid black\" > </hr >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "- https://machinelearningmastery.com/\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
